# -*- coding: utf-8 -*-
import asyncio
import telegram
import json
import logging
import inspect
from typing import Dict, Any
from datetime import datetime
from langchain.memory import ConversationSummaryMemory
from langchain_ollama import ChatOllama
from langchain_core.messages import SystemMessage, HumanMessage
from httpx import ConnectError

from telegram import Update
from telegram.ext import ContextTypes

import config
from ai import prompts, tools
import database
from handlers import standard_handlers

logger = logging.getLogger(__name__)

# Ø­Ø§ÙØ¸Ù‡ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ú©Ø§Ø±Ø¨Ø± (Ú©Ù„ÛŒØ¯: user_id)
memories = {}

def get_memory(user_id: str) -> ConversationSummaryMemory:
    """Ø­Ø§ÙØ¸Ù‡ Ø®Ù„Ø§ØµÙ‡â€ŒØ´Ø¯Ù‡ Ù…Ú©Ø§Ù„Ù…Ù‡ Ù‡Ø± Ú©Ø§Ø±Ø¨Ø± Ø±Ùˆ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯ÙˆÙ†Ù‡ ÛŒØ§ Ø§ÛŒØ¬Ø§Ø¯ Ù…ÛŒâ€ŒÚ©Ù†Ù‡."""
    if user_id not in memories:
        memories[user_id] = ConversationSummaryMemory(llm=ChatOllama(model=config.OLLAMA_MODEL, base_url=config.OLLAMA_BASE_URL))
    return memories[user_id]

async def execute_plan(plan: Dict[str, Any], user_input: str, update: Update, context: ContextTypes.DEFAULT_TYPE, placeholder_message_id: int) -> bool:
    """Ù†Ù‚Ø´Ù‡ Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    try:
        if not plan or 'steps' not in plan or not plan['steps']:
            await context.bot.edit_message_text(chat_id=update.effective_chat.id, message_id=placeholder_message_id, text="Ù…ØªØ§Ø³ÙØ§Ù†Ù‡ Ù†Ù‚Ø´Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            return False

        first_step = plan['steps'][0]
        tool_name = first_step.get("tool_name")
        tool_function = tools.TOOL_MAPPING.get(tool_name)

        if not tool_function:
            await context.bot.edit_message_text(chat_id=update.effective_chat.id, message_id=placeholder_message_id, text=f"âš ï¸ Ø§Ø¨Ø²Ø§Ø± '{tool_name}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            return False

        arguments = first_step.get("arguments", {})
        logger.info(f"Ø´Ø±ÙˆØ¹ Ø§Ø¬Ø±Ø§ÛŒ Ú¯Ø§Ù… Û±/Û±: Ø§Ø¨Ø²Ø§Ø±='{tool_name}', Ø¢Ø±Ú¯ÙˆÙ…Ø§Ù†â€ŒÙ‡Ø§={arguments}")

        sig = inspect.signature(tool_function)
        if 'update' in sig.parameters: arguments['update'] = update
        if 'context' in sig.parameters: arguments['context'] = context

        result = await tool_function(**arguments)

        if result is not None:
            final_message = result.get('message', 'Ø¹Ù…Ù„ÛŒØ§Øª Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.')
            if url := result.get('url'):
                final_message += f"\n\nğŸ”— *Ù„ÛŒÙ†Ú© ØªØ³Ú©:* {url}"
            await context.bot.edit_message_text(chat_id=update.effective_chat.id, message_id=placeholder_message_id, text=final_message, parse_mode='Markdown')
        else:
            logger.info(f"Ø§Ø¨Ø²Ø§Ø± ØªØ¹Ø§Ù…Ù„ÛŒ '{tool_name}' Ø§Ø¬Ø±Ø§ Ø´Ø¯ Ùˆ Ù…Ù†ØªØ¸Ø± ÙˆØ±ÙˆØ¯ÛŒ Ú©Ø§Ø±Ø¨Ø± Ø§Ø³Øª.")

        return True
    
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ Ø§Ø¨Ø²Ø§Ø± '{tool_name}': {e}", exc_info=True)
        await context.bot.edit_message_text(chat_id=update.effective_chat.id, message_id=placeholder_message_id, text=f"âŒ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ Ø¯Ø³ØªÙˆØ± Ø´Ù…Ø§ Ø®Ø·Ø§ Ø±Ø® Ø¯Ø§Ø¯: {str(e)}")
        return False

def log_chat_to_db(user_id: str, user_name: str, user_message: str, bot_response: str, success: bool, error_message: str = None):
    """Ù…Ú©Ø§Ù„Ù…Ù‡â€ŒÙ‡Ø§ Ø±Ùˆ ØªÙˆÛŒ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ú†Øª Appwrite Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ù‡."""
    data = {'user_id': user_id, 'user_name': user_name, 'user_message': user_message, 'bot_response': bot_response, 'success': success, 'error_message': error_message, 'timestamp': datetime.now().isoformat()}
    try:
        database.create_document(config.APPWRITE_CHAT_DATABASE_ID, config.CHAT_LOGS_COLLECTION_ID, data)
        logger.info(f"Ù„Ø§Ú¯ Ù…Ú©Ø§Ù„Ù…Ù‡ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø± {user_id} Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ù„Ø§Ú¯ Ù…Ú©Ø§Ù„Ù…Ù‡ Ø¯Ø± Appwrite: {e}", exc_info=True)

async def ai_handler_entry(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = str(update.effective_user.id)
    
    # The primary authentication check. This function checks memory first, then DB.
    # It also sets the 'is_authenticated' flag in user_data and messages the user if they are not found.
    clickup_token = await standard_handlers._get_user_token(user_id, update, context)
    if not clickup_token:
        # The _get_user_token function already sent a message, so we just exit.
        logger.warning(f"AI handler: User {user_id} is not authenticated. Aborting.")
        return

    user_input = update.message.text
    user_name = update.message.from_user.username or "Unknown"
    
    placeholder_message = await context.bot.send_message(chat_id=update.effective_chat.id, text="Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø´Ù…Ø§... â³")
    
    logger.info(f"Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¬Ø¯ÛŒØ¯ Ø§Ø² Ú©Ø§Ø±Ø¨Ø± '{user_name}' ({user_id}): '{user_input}'")
    
    memory = get_memory(user_id)
    history = memory.chat_memory.messages
    await update.message.chat.send_action(action='typing')
    routing_messages = [SystemMessage(content=prompts.TOOL_ROUTER_PROMPT)] + history + [HumanMessage(content=user_input)]

    llm_router = ChatOllama(model=config.OLLAMA_MODEL, base_url=config.OLLAMA_BASE_URL, format="json", temperature=0)
    try:
        response = await llm_router.ainvoke(routing_messages)
        logger.info(f"Ù¾Ø§Ø³Ø® Ø®Ø§Ù… Ø§Ø² Ù…Ø³ÛŒØ±ÛŒØ§Ø¨ LLM:\n{response.content}")
        
        plan = json.loads(response.content)
        tool_name = plan.get('steps', [{}])[0].get('tool_name', 'no_op')
        logger.info(f"Ø§Ø¨Ø²Ø§Ø± Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡ ØªÙˆØ³Ø· Ù…Ø³ÛŒØ±ÛŒØ§Ø¨: '{tool_name}'")
        
        if tool_name == 'no_op':
            logger.info("ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ù…Ø­Ø§ÙˆØ±Ù‡â€ŒØ§ÛŒ...")
            chat_prompt_text = prompts.CHAT_PROMPT.format(user_input=user_input)
            llm_chat = ChatOllama(model=config.OLLAMA_MODEL, base_url=config.OLLAMA_BASE_URL, temperature=0.7)
            chat_response = await llm_chat.ainvoke([SystemMessage(content=chat_prompt_text)] + history + [HumanMessage(content=user_input)])
            final_response_text = chat_response.content
            logger.info(f"Ù¾Ø§Ø³Ø® Ù†Ù‡Ø§ÛŒÛŒ Ù…Ø­Ø§ÙˆØ±Ù‡â€ŒØ§ÛŒ:\n{final_response_text}")
            
            await placeholder_message.edit_text(final_response_text)
            memory.save_context({"input": user_input}, {"output": chat_response.content})
            log_chat_to_db(user_id, user_name, user_input, chat_response.content, True)
        else:
            logger.info(f"Ø§Ø¬Ø±Ø§ÛŒ Ù†Ù‚Ø´Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ø¨Ø²Ø§Ø± '{tool_name}'...")
            success = await execute_plan(plan, user_input, update, context, placeholder_message.message_id)
            if not inspect.iscoroutinefunction(tools.TOOL_MAPPING.get(tool_name)):
                 memory.save_context({"input": user_input}, {"output": response.content})
                 log_chat_to_db(user_id, user_name, user_input, response.content, success)

    except ConnectError:
        logger.critical("Ø¹Ø¯Ù… Ø§Ù…Ú©Ø§Ù† Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø³Ø±ÙˆÛŒØ³ Ollama. Ø¢ÛŒØ§ Ø³Ø±ÙˆÛŒØ³ Ø¯Ø± Ø­Ø§Ù„ Ø§Ø¬Ø±Ø§ Ø§Ø³ØªØŸ", exc_info=True)
        await placeholder_message.edit_text("âŒ Ø§Ù…Ú©Ø§Ù† Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø³Ø±ÙˆÛŒØ³ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯. Ù„Ø·ÙØ§Ù‹ Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒØ¯ Ú©Ù‡ Ollama Ø¯Ø± Ø­Ø§Ù„ Ø§Ø¬Ø±Ø§ Ø§Ø³Øª.")
        log_chat_to_db(user_id, user_name, user_input, "ConnectError to Ollama", False, "Ollama not running or accessible")
    except json.JSONDecodeError:
        logger.error(f"Ù¾Ø§Ø³Ø® JSON Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø² LLM", exc_info=True)
        await placeholder_message.edit_text("ğŸš¨ Ø®Ø·Ø§: Ù¾Ø§Ø³Ø® Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø² Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯.")
        log_chat_to_db(user_id, user_name, user_input, "Invalid JSON Response", False, "JSONDecodeError")
    except Exception as e:
        logger.critical(f"Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‡ÙˆØ´Ù…Ù†Ø¯: {e}", exc_info=True)
        await placeholder_message.edit_text(f"ğŸš¨ ÛŒÚ© Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ø±Ø® Ø¯Ø§Ø¯: {str(e)}")
        log_chat_to_db(user_id, user_name, user_input, str(e), False, str(e))

